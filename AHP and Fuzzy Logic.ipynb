{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o6dOkxYwWUnu","outputId":"e850a5ed-3270-4be4-b7cb-29ff815fdb10","executionInfo":{"status":"ok","timestamp":1728405751895,"user_tz":-480,"elapsed":15090,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n","Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.4.1+cu121)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->torchaudio) (3.1.4)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->torchaudio) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->torchaudio) (1.3.0)\n","Requirement already satisfied: scikit-fuzzy in /usr/local/lib/python3.10/dist-packages (0.5.0)\n","Requirement already satisfied: ahpy in /usr/local/lib/python3.10/dist-packages (2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ahpy) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from ahpy) (1.13.1)\n","Requirement already satisfied: PyDrive in /usr/local/lib/python3.10/dist-packages (1.3.1)\n","Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (2.137.0)\n","Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (4.1.3)\n","Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.10/dist-packages (from PyDrive) (6.0.2)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.22.0)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (2.27.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.2.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (2.19.2)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.2->PyDrive) (4.1.1)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.6.1)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.1)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.9)\n","Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.16.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.65.0)\n","Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.20.3)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (1.24.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.2->PyDrive) (5.5.0)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=1.2->PyDrive) (3.1.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.2->PyDrive) (2024.8.30)\n"]}],"source":["# Install necessary packages\n","!pip install transformers datasets torchaudio librosa pandas\n","!pip install scikit-fuzzy\n","!pip install ahpy\n","!pip install PyDrive"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"LPoCxV9sWXY9","executionInfo":{"status":"ok","timestamp":1728405751895,"user_tz":-480,"elapsed":5,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[],"source":["# Import necessary libraries\n","import os\n","import torch\n","import gc\n","import librosa\n","import pandas as pd\n","import numpy as np\n","import math\n","import skfuzzy as fuzz\n","import skfuzzy.control as ctrl\n","from ahpy import Compare\n","from google.colab import files, drive, auth\n","from google.colab import drive\n","from oauth2client.client import GoogleCredentials\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from torch.utils.data import Dataset\n","from transformers import (\n","    AutoModelForAudioClassification, Wav2Vec2FeatureExtractor,\n","    AutoTokenizer, MobileBertForSequenceClassification,\n","    BigBirdForSequenceClassification, Trainer, TrainingArguments,\n","    DataCollatorWithPadding\n",")\n","import joblib\n","import torch.nn.functional as F\n","\n","# Set device to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"nI_NSByMWfQ5","executionInfo":{"status":"ok","timestamp":1728405751895,"user_tz":-480,"elapsed":5,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[],"source":["# ---------------------------------------\n","# Emotion Recognition Module\n","# ---------------------------------------\n","\n","class PretrainedEmotionModel:\n","    \"\"\"\n","    Use the pre-trained DistilHuBERT model from Hugging Face for emotion classification.\n","    \"\"\"\n","    def __init__(self, model_name):\n","        # Load the pre-trained DistilHuBERT model and feature extractor\n","        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n","        self.model = AutoModelForAudioClassification.from_pretrained(model_name)\n","\n","    def predict_all_labels(self, audio_file_path):\n","        \"\"\"\n","        Predict all possible emotion labels with their respective confidence scores.\n","        \"\"\"\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        # Load and preprocess the audio\n","        speech_array, sampling_rate = librosa.load(audio_file_path, sr=16000)\n","        inputs = self.feature_extractor(\n","            speech_array, return_tensors=\"pt\", sampling_rate=sampling_rate, padding=True\n","        )\n","\n","        # Move inputs and model to the appropriate device (GPU or CPU)\n","        inputs = {key: value.to(device) for key, value in inputs.items()}\n","        self.model.to(device)\n","\n","        # Make predictions\n","        with torch.no_grad():\n","            logits = self.model(**inputs).logits\n","            probabilities = torch.softmax(logits, dim=-1).squeeze().cpu().numpy()\n","\n","        # Map label IDs to emotion labels\n","        id2label = self.model.config.id2label\n","\n","        # Collect the predictions and their associated confidence scores\n","        results = []\n","        for label_id, confidence in enumerate(probabilities):\n","            emotion = id2label[label_id]\n","            results.append({\n","                'audio_file': os.path.basename(audio_file_path),\n","                'emotion': emotion.capitalize(),\n","                'confidence': confidence\n","            })\n","\n","        # Sort results by confidence in descending order\n","        df = pd.DataFrame(results)\n","        df = df.sort_values(by='confidence', ascending=False).reset_index(drop=True)\n","\n","        return df\n","\n","\n","class EmotionPipeline:\n","    \"\"\"\n","    Orchestrates the workflow of downloading audio data from Google Drive and performing emotion classification.\n","    \"\"\"\n","    def __init__(self, model_name=\"pollner/distilhubert-finetuned-ravdess\"):\n","        self.model_name = model_name\n","        self.model = PretrainedEmotionModel(self.model_name)\n","\n","    def authenticate_and_create_drive(self):\n","        \"\"\"\n","        Authenticates the user and creates a PyDrive GoogleDrive instance.\n","        \"\"\"\n","        auth.authenticate_user()\n","        gauth = GoogleAuth()\n","        gauth.credentials = GoogleCredentials.get_application_default()\n","        drive = GoogleDrive(gauth)\n","        return drive\n","\n","    def download_audio_from_drive(self, drive, audio_file_id, destination_path):\n","        \"\"\"\n","        Downloads an audio file from Google Drive using its file ID.\n","        \"\"\"\n","        print(f\"Downloading audio file from Google Drive with file ID: {audio_file_id}\")\n","        downloaded = drive.CreateFile({'id': audio_file_id})\n","        downloaded.GetContentFile(destination_path)\n","        print(f\"Downloaded audio file and saved as {destination_path}\")\n","\n","    def load_and_predict(self, audio_file_ids):\n","        \"\"\"\n","        Downloads the audio files using their file IDs and predicts all possible labels.\n","        \"\"\"\n","        drive = self.authenticate_and_create_drive()\n","\n","        for audio_file_name, audio_file_id in audio_file_ids.items():\n","            destination_path = f\"./{audio_file_name}\"\n","            self.download_audio_from_drive(drive, audio_file_id, destination_path)\n","\n","            # Perform prediction using the pre-trained model\n","            result_df = self.model.predict_all_labels(destination_path)\n","        return result_df"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"K0I7LhzvWsbU","executionInfo":{"status":"ok","timestamp":1728405751895,"user_tz":-480,"elapsed":4,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[],"source":["# ---------------------------------------\n","# Sentiment Analysis Module\n","# ---------------------------------------\n","\n","class TextSentimentAnalysisPipeline:\n","    def __init__(self, dataset_path, model_name='cambridgeltl/sst_mobilebert-uncased'):\n","        with open(dataset_path, 'r') as file:\n","            self.conversation = [line.strip() for line in file.readlines()]\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n","        self.model = MobileBertForSequenceClassification.from_pretrained(model_name)\n","        self.model.eval()  # Set model to evaluation mode\n","\n","    def extract_caller_text(self):\n","        # Extract lines spoken by the \"Caller\"\n","        caller_lines = [line.lstrip('\"Caller: ').rstrip('\", ').split('. ') for line in self.conversation if line.startswith('\"Caller:')]\n","        caller_lines = [sentence for sublist in caller_lines for sentence in sublist]\n","        return caller_lines\n","\n","    def predict_sentiments(self, texts):\n","        inputs = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","        outputs = self.model(**inputs)\n","        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n","        return probs.detach().numpy()\n","\n","    def evaluate(self):\n","        # Extract all text spoken by the Caller\n","        caller_text = self.extract_caller_text()\n","\n","        # Predict sentiments and get confidence scores\n","        result = []\n","        for turn in caller_text:\n","          prob = self.predict_sentiments(turn)\n","          result.append({\n","              'Sentence': turn,\n","              'Positive Confidence': prob[0, 2],\n","              'Negative Confidence': prob[0, 0],\n","              'Neutral Confidence': prob[0, 1]\n","        })\n","        result_df = pd.DataFrame(result)\n","        avg_pos = result_df['Positive Confidence'].mean()\n","        avg_neg = result_df['Negative Confidence'].mean()\n","        avg_neu = result_df['Neutral Confidence'].mean()\n","        sentiment_df = pd.DataFrame({'sentiment':['Positive', 'Negative', 'Neutral'], 'confidence':[avg_pos, avg_neg, avg_neu]})\n","        return sentiment_df"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"PrFfiVScWuhy","executionInfo":{"status":"ok","timestamp":1728405751895,"user_tz":-480,"elapsed":4,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[],"source":["# ---------------------------------------\n","# Coherence Evaluation Module\n","# ---------------------------------------\n","\n","# Step 1: Class for defining the custom dataset\n","class DialogueDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length):\n","        self.dataframe = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        context = self.dataframe.iloc[idx, 0]\n","        response = self.dataframe.iloc[idx, 1]\n","        label = self.dataframe.iloc[idx, 2]\n","\n","        combined_text = context + \" \" + self.tokenizer.sep_token + \" \" + response\n","        encoding = self.tokenizer(\n","            combined_text,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\",\n","        )\n","\n","        input_ids = encoding[\"input_ids\"].squeeze(0)\n","        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n","\n","        return {\n","            \"input_ids\": input_ids,\n","            \"attention_mask\": attention_mask,\n","            \"labels\": torch.tensor(label, dtype=torch.long),\n","        }\n","\n","# Step 2: Class for model training\n","class ModelTrainer:\n","    def __init__(self, train_dataset):\n","        self.tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n","        self.model = BigBirdForSequenceClassification.from_pretrained('google/bigbird-roberta-base')\n","        self.train_dataset = train_dataset\n","        self.training_args = self._setup_training_args()\n","        for name, param in self.model.named_parameters():\n","          if not param.is_contiguous():\n","            #print(f'Making contiguous:{name}')\n","            param.data = param.data.contiguous()\n","        #for name, param in self.model.named_parameters():\n","            #print(f'Layer:{name}, Contiguous:{param.is_contiguous()}')\n","\n","    def _setup_training_args(self):\n","        # Set up training arguments, limiting to 1 epoch for quick testing\n","        return TrainingArguments(\n","            output_dir='./results',\n","            num_train_epochs=1,  # Quick testing with 1 epoch\n","            per_device_train_batch_size=8,\n","            learning_rate=2e-5,\n","            warmup_steps=500,\n","            weight_decay=0.01,\n","            logging_dir='./logs',\n","            logging_steps=50,\n","            save_total_limit=2,\n","            save_steps=200,\n","            evaluation_strategy=\"no\",\n","        )\n","\n","    def fine_tune_model(self):\n","        trainer = Trainer(\n","            model=self.model,\n","            args=self.training_args,\n","            train_dataset=self.train_dataset\n","        )\n","        trainer.train()\n","        return self.model\n","\n","    def save_model(self, save_path):\n","        self.model.save_pretrained(save_path)\n","        self.tokenizer.save_pretrained(save_path)\n","        print(f\"Model saved to {save_path}\")\n","\n","# Step 3: Class for coherence evaluation\n","class CoherenceEvaluator:\n","    def __init__(self, model_path):\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n","        self.model = BigBirdForSequenceClassification.from_pretrained(model_path)\n","\n","    def tokenize_input(self, context, response):\n","        return self.tokenizer(context, response, return_tensors='pt', max_length=1024, truncation=True, padding='max_length')\n","\n","    def compute_logits(self, inputs):\n","        outputs = self.model(**inputs)\n","        return outputs.logits\n","\n","    def apply_softmax(self, logits):\n","        probabilities = F.softmax(logits, dim=1)\n","        return probabilities[0][1].item()\n","\n","# Step 4: Main pipeline class to encapsulate the entire process\n","class CoherencePipeline:\n","    def __init__(self, dataset_path, model_save_path, load_model=False):\n","        self.file_path = dataset_path\n","        self.model_save_path = model_save_path\n","        self.load_model = load_model\n","        self.model_trainer = None\n","        self.coherence_evaluator = None\n","\n","    def prepare_dataset(self):\n","        df = pd.read_csv(self.file_path)\n","        tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n","        train_dataset = DialogueDataset(df, tokenizer, max_length=256)\n","        return train_dataset\n","\n","    def train_and_save_model(self, train_dataset):\n","        self.model_trainer = ModelTrainer(train_dataset)\n","        trained_model = self.model_trainer.fine_tune_model()\n","        self.model_trainer.save_model(self.model_save_path)\n","        return trained_model\n","\n","    def evaluate_coherence(self):\n","        #file_name = list(self.file_path.keys())[0]\n","        with open(self.file_path, 'r') as file:\n","            dialogue = file.readlines()\n","\n","        self.coherence_evaluator = CoherenceEvaluator(self.model_save_path)\n","        pairs = [(dialogue[i].strip(), dialogue[i + 1].strip()) for i in range(len(dialogue) - 1)]\n","\n","        scores = []\n","        for context, response in pairs:\n","            inputs = self.coherence_evaluator.tokenize_input(context, response)\n","            logits = self.coherence_evaluator.compute_logits(inputs)\n","            score = self.coherence_evaluator.apply_softmax(logits)\n","            scores.append(score)\n","\n","        # Create DataFrame to store results\n","        df_results = pd.DataFrame({\n","            'Pair Number': [f'Pair {i+1}' for i in range(len(pairs))],\n","            'Context': [pair[0] for pair in pairs],\n","            'Response': [pair[1] for pair in pairs],\n","            'Coherence Score': scores\n","        })\n","\n","        # Calculate overall coherence score\n","        overall_score = sum(scores) / len(scores)\n","        df_results.loc['Overall'] = ['', '', 'Overall Coherence Score', overall_score]\n","\n","        return df_results\n","\n","    def run_pipeline(self):\n","        if self.load_model:\n","            # Check if fine-tuned model exists\n","            if self.model_save_path.startswith('google/'):\n","              print(f'Using pretrained model from Hugging Face:{self.model_save_path}')\n","            else:\n","                if not os.path.exists(self.model_save_path):\n","                    raise FileNotFoundError(f\"No fine-tuned model found at {self.model_save_path}. Please train the model first.\")\n","                print(f\"Using existing model from {self.model_save_path}\")\n","        else:\n","            # Train model if flag is set to True\n","            train_dataset = self.prepare_dataset()\n","            self.train_and_save_model(train_dataset)\n","\n","        # Proceed to evaluate test data\n","        df_results = self.evaluate_coherence()\n","        print(df_results)\n","        return df_results"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"aHJFcUb7Wh4p","executionInfo":{"status":"ok","timestamp":1728405751895,"user_tz":-480,"elapsed":4,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[],"source":["# ---------------------------------------\n","# Utility Functions Module\n","# ---------------------------------------\n","\n","def map_emotion_to_score(emotion):\n","    \"\"\"\n","    Maps emotion labels to numerical scores.\n","    \"\"\"\n","    emotion_scores = {\n","        'Happy': 1,\n","        'Neutral': 0,\n","        'Calm': 0,\n","        'Angry': -1,\n","        'Disgust': -1,\n","        'Surprised': -1,\n","        'Fearful': -1,\n","        'Sad': -1\n","    }\n","    return emotion_scores.get(emotion, 0)\n","\n","def map_sentiment_to_score(sentiment):\n","    \"\"\"\n","    Maps sentiment labels to numerical scores.\n","    \"\"\"\n","    sentiment_scores = {'Neutral': 0, 'Negative': -1, 'Positive': 1}\n","    return sentiment_scores.get(sentiment, 0)\n","\n","def sigmoid_transform(x):\n","    \"\"\"\n","    Applies a sigmoid transformation and scales the result.\n","    \"\"\"\n","    x_sigmoid = 1 / (1 + math.exp(-x))\n","    x_scaled = x_sigmoid * 10\n","    return x_scaled\n","\n","def calculate_weighted_score(df):\n","    \"\"\"\n","    Calculates the final weighted score from a DataFrame containing emotion or sentiment data.\n","    \"\"\"\n","    if 'emotion' in df.columns:\n","        # Process DataFrame with emotions\n","        df['score'] = df['emotion'].apply(map_emotion_to_score)\n","        df['weighted_score'] = df['score'] * df['confidence']\n","    elif 'sentiment' in df.columns:\n","        # Process DataFrame with sentiments\n","        df['score'] = df['sentiment'].apply(map_sentiment_to_score)\n","        df['weighted_score'] = df['score'] * df['confidence']\n","    else:\n","        raise ValueError(\"DataFrame format not recognized.\")\n","\n","    weighted_sum = df['weighted_score'].sum()\n","    total_confidence = df['confidence'].sum()\n","    weighted_score_raw = weighted_sum / total_confidence if total_confidence != 0 else 0\n","    weighted_score = sigmoid_transform(weighted_score_raw)\n","    return weighted_score"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"YAc73GzJWz0Y","executionInfo":{"status":"ok","timestamp":1728407132040,"user_tz":-480,"elapsed":747,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}}},"outputs":[],"source":["# ---------------------------------------\n","# AHP and Fuzzy Logic Module\n","# ---------------------------------------\n","\n","class ScoringSystem:\n","    \"\"\"\n","    Implements AHP weight calculation, consistency ratio verification, and fuzzy logic scoring.\n","    \"\"\"\n","    def __init__(self):\n","        self.weights = None\n","\n","    def calculate_ahp_weights(self):\n","        \"\"\"\n","        Calculates AHP weights and checks consistency ratio.\n","        \"\"\"\n","        # AHP Weight Calculation\n","        criteria = ['Emotion Score', 'Sentiment Score', 'Coherence Score']\n","        pairwise_comparisons = {\n","            ('Emotion Score', 'Sentiment Score'): 2,  # Emotion Score is slightly important than Sentiment Score\n","            ('Emotion Score', 'Coherence Score'): 3,  # Emotion Score is moderate important than Coherence Score\n","            ('Sentiment Score', 'Coherence Score'): 3  # Sentiment Score is moderate important than Coherence Score\n","        }\n","\n","        comparison = Compare('Criteria', pairwise_comparisons, precision=3, random_index='saaty')\n","        report = comparison.report(show=True)\n","\n","        self.weights = report['target_weights']\n","        consistency_ratio = report['elements']['consistency_ratio']\n","\n","        # Check Consistency Ratio (CR) to ensure AHP consistency\n","        if consistency_ratio > 0.1:\n","            raise ValueError(f\"Consistency Ratio (CR) is too high: {consistency_ratio:.3f}. The pairwise comparisons may be inconsistent.\")\n","        else:\n","            print(f\"Consistency Ratio (CR): {consistency_ratio:.3f} (acceptable)\")\n","\n","        print(\"AHP Weights:\", self.weights)\n","\n","    def perform_fuzzy_logic_scoring(self, emotion_score, sentiment_score, coherence_score):\n","        \"\"\"\n","        Performs fuzzy logic scoring using the calculated AHP weights.\n","        \"\"\"\n","        # Define fuzzy variables and membership functions\n","        x_range = np.arange(0, 10.1, 0.1)\n","        emotion_score_fuzzy = ctrl.Antecedent(x_range, 'emotion_score')\n","        sentiment_score_fuzzy = ctrl.Antecedent(x_range, 'sentiment_score')\n","        coherence_score_fuzzy = ctrl.Antecedent(x_range, 'coherence_score')\n","        final_score_fuzzy = ctrl.Consequent(x_range, 'final_score')\n","\n","        # Define membership functions for input variables\n","        for fuzzy_var in [emotion_score_fuzzy, sentiment_score_fuzzy, coherence_score_fuzzy]:\n","          fuzzy_var['low'] = fuzz.trimf(fuzzy_var.universe, [0, 0, 1.5])\n","          fuzzy_var['medium'] = fuzz.trimf(fuzzy_var.universe, [1, 3, 6])\n","          fuzzy_var['high'] = fuzz.trimf(fuzzy_var.universe, [5, 10, 10])\n","\n","        # Define membership functions for the output variable\n","        final_score_fuzzy['low'] = fuzz.trimf(final_score_fuzzy.universe, [0, 0, 1.5])\n","        final_score_fuzzy['medium'] = fuzz.trimf(final_score_fuzzy.universe, [1, 3, 6])\n","        final_score_fuzzy['high'] = fuzz.trimf(final_score_fuzzy.universe, [5, 10, 10])\n","\n","        # Define fuzzy rules\n","        # Rule 1: If all indicators are high, then the final score is high.\n","        rule1 = ctrl.Rule(\n","            emotion_score_fuzzy['high'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['high'],\n","            final_score_fuzzy['high']\n","        )\n","\n","        # Rule 2: If two indicators are high and one is medium, then the final score is high.\n","        rule2 = ctrl.Rule(\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['high']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['high']),\n","            final_score_fuzzy['high']\n","        )\n","\n","        # Rule 3: If two indicators are high and one is low, then the final score is medium.\n","        rule3 = ctrl.Rule(\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['low']) |\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['high']) |\n","            (emotion_score_fuzzy['low'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['high']),\n","            final_score_fuzzy['medium']\n","        )\n","\n","        # Rule 4: If all indicators are medium, then the final score is medium.\n","        rule4 = ctrl.Rule(\n","            emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['medium'],\n","            final_score_fuzzy['medium']\n","        )\n","\n","        # Rule 5: If one indicator is high and two are medium, then the final score is medium.\n","        rule5 = ctrl.Rule(\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['high']),\n","            final_score_fuzzy['medium']\n","        )\n","\n","        # Rule 6: If two indicators are medium and one is low, then the final score is medium.\n","        rule6 = ctrl.Rule(\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['low']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['low'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['medium']),\n","            final_score_fuzzy['medium']\n","        )\n","\n","        # Rule 7: If all indicators are low, then the final score is low.\n","        rule7 = ctrl.Rule(\n","            emotion_score_fuzzy['low'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['low'],\n","            final_score_fuzzy['low']\n","        )\n","\n","        # Rule 8: If two indicators are low and one is medium, then the final score is low.\n","        rule8 = ctrl.Rule(\n","            (emotion_score_fuzzy['low'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['low'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['low']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['low']),\n","            final_score_fuzzy['low']\n","        )\n","\n","        # Rule 9: If one indicator is high, one medium, and one low, then the final score is medium.\n","        rule9 = ctrl.Rule(\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['low']) |\n","            (emotion_score_fuzzy['high'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['low']) |\n","            (emotion_score_fuzzy['medium'] & sentiment_score_fuzzy['low'] & coherence_score_fuzzy['high']) |\n","            (emotion_score_fuzzy['low'] & sentiment_score_fuzzy['high'] & coherence_score_fuzzy['medium']) |\n","            (emotion_score_fuzzy['low'] & sentiment_score_fuzzy['medium'] & coherence_score_fuzzy['high']),\n","            final_score_fuzzy['medium']\n","        )\n","\n","        # Create control system and simulation\n","        scoring_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])\n","        scoring = ctrl.ControlSystemSimulation(scoring_ctrl)\n","\n","        # Calculate weighted scores\n","        weighted_emotion_score = emotion_score * self.weights['Emotion Score']\n","        weighted_sentiment_score = sentiment_score * self.weights['Sentiment Score']\n","        weighted_coherence_score = coherence_score * self.weights['Coherence Score']\n","\n","        print(f\"Weighted Emotion Score: {weighted_emotion_score:.2f}\")\n","        print(f\"Weighted Sentiment Score: {weighted_sentiment_score:.2f}\")\n","        print(f\"Weighted Coherence Score: {weighted_coherence_score:.2f}\")\n","\n","        # Input weighted scores into fuzzy system\n","        scoring.input['emotion_score'] = weighted_emotion_score\n","        scoring.input['sentiment_score'] = weighted_sentiment_score\n","        scoring.input['coherence_score'] = weighted_coherence_score\n","\n","        # Perform fuzzy inference\n","        scoring.compute()\n","\n","        # Output final score\n","        final_score_value_no_fuzzy = weighted_emotion_score + weighted_sentiment_score + weighted_coherence_score\n","        final_score_value = scoring.output['final_score']\n","        return final_score_value_no_fuzzy, final_score_value"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LE34FBvjXgfL","executionInfo":{"status":"ok","timestamp":1728407169891,"user_tz":-480,"elapsed":35047,"user":{"displayName":"Arc Lich","userId":"02724969290719725870"}},"outputId":"3305eeda-7aa3-4d23-ad60-3fc5eb4cf5cc"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at pollner/distilhubert-finetuned-ravdess were not used when initializing HubertForSequenceClassification: ['hubert.encoder.pos_conv_embed.conv.weight_g', 'hubert.encoder.pos_conv_embed.conv.weight_v']\n","- This IS expected if you are initializing HubertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing HubertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of HubertForSequenceClassification were not initialized from the model checkpoint at pollner/distilhubert-finetuned-ravdess and are newly initialized: ['hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'hubert.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Downloading audio file from Google Drive with file ID: 108kPpEQeA_6RkQXmmLWDJXQzdiISlm0r\n","Downloaded audio file and saved as ./audio1.mp3\n","Audio Emotion Results:\n","   audio_file    emotion  confidence\n","0  audio1.mp3    Neutral    0.606273\n","1  audio1.mp3        Sad    0.158475\n","2  audio1.mp3      Happy    0.151102\n","3  audio1.mp3       Calm    0.070715\n","4  audio1.mp3    Disgust    0.005959\n","5  audio1.mp3      Angry    0.003035\n","6  audio1.mp3  Surprised    0.002574\n","7  audio1.mp3    Fearful    0.001867\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Text Sentiment Results:\n","  sentiment  confidence\n","0  Positive    0.415585\n","1  Negative    0.193286\n","2   Neutral    0.391129\n","Emotion Score: 4.95\n","Sentiment Score: 5.55\n","Using existing model from ./coherence_model\n","        Pair Number                                            Context  \\\n","0            Pair 1  [\"AI: Hi, my name is Lila. I'm Octivo's AI age...   \n","1            Pair 2  \"Caller: Hey, nice to meet you. My name is Mic...   \n","2            Pair 3  \"AI: Thank you for introducing yourself Michae...   \n","3            Pair 4  \"Caller: Yeah, sure. I'm 27 but I feel like I ...   \n","4            Pair 5  \"AI: I completely understand your hesitation a...   \n","5            Pair 6  \"Caller: Ok, that's fair enough. So I'm earnin...   \n","6            Pair 7  \"AI: Thank you for sharing your income range t...   \n","7            Pair 8  \"Caller: I will retire at around 65 and I woul...   \n","Overall                                                                  \n","\n","                                                  Response  Coherence Score  \n","0        \"Caller: Hey, nice to meet you. My name is Mic...         0.590054  \n","1        \"AI: Thank you for introducing yourself Michae...         0.766010  \n","2        \"Caller: Yeah, sure. I'm 27 but I feel like I ...         0.754133  \n","3        \"AI: I completely understand your hesitation a...         0.769230  \n","4        \"Caller: Ok, that's fair enough. So I'm earnin...         0.767711  \n","5        \"AI: Thank you for sharing your income range t...         0.761523  \n","6        \"Caller: I will retire at around 65 and I woul...         0.762877  \n","7        \"AI: It was an absolute pleasure assisting you...         0.767307  \n","Overall                            Overall Coherence Score         0.742356  \n","Coherence Score: 7.42\n","{\n","    \"name\": \"Criteria\",\n","    \"global_weight\": 1.0,\n","    \"local_weight\": 1.0,\n","    \"target_weights\": {\n","        \"Emotion Score\": 0.528,\n","        \"Sentiment Score\": 0.333,\n","        \"Coherence Score\": 0.14\n","    },\n","    \"elements\": {\n","        \"global_weights\": {\n","            \"Emotion Score\": 0.528,\n","            \"Sentiment Score\": 0.333,\n","            \"Coherence Score\": 0.14\n","        },\n","        \"local_weights\": {\n","            \"Emotion Score\": 0.528,\n","            \"Sentiment Score\": 0.333,\n","            \"Coherence Score\": 0.14\n","        },\n","        \"consistency_ratio\": 0.052\n","    }\n","}\n","Consistency Ratio (CR): 0.052 (acceptable)\n","AHP Weights: {'Emotion Score': 0.528, 'Sentiment Score': 0.333, 'Coherence Score': 0.14}\n","Weighted Emotion Score: 2.61\n","Weighted Sentiment Score: 1.85\n","Weighted Coherence Score: 1.04\n","Final Score (without Fuzzy Logic): 5.50\n","Final Score (Defuzzified): 3.43\n"]}],"source":["# ---------------------------------------\n","# Main Function\n","# ---------------------------------------\n","\n","def main():\n","    # ---------------------------\n","    # Emotion Recognition\n","    # ---------------------------\n","    audio_model_name = \"pollner/distilhubert-finetuned-ravdess\"\n","\n","    # Initialize the pipeline with the pre-trained model\n","    emotion_pipeline = EmotionPipeline(model_name=audio_model_name)\n","\n","    # Provide the Google Drive file IDs of the audio files\n","    audio_file_ids = {\n","        'audio1.mp3': '108kPpEQeA_6RkQXmmLWDJXQzdiISlm0r'\n","    }\n","\n","    # Download the audio files and perform emotion prediction\n","    audio_results_df = emotion_pipeline.load_and_predict(audio_file_ids)\n","    print(\"Audio Emotion Results:\")\n","    print(audio_results_df)\n","\n","    # ---------------------------\n","    # Sentiment Analysis\n","    # ---------------------------\n","    test_data_path = './dialogue1.txt'  # Ensure this file exists\n","    sentiment_pipeline = TextSentimentAnalysisPipeline(test_data_path)\n","    text_results_df = sentiment_pipeline.evaluate()\n","    print(\"Text Sentiment Results:\")\n","    print(text_results_df)\n","\n","    # ---------------------------\n","    # Calculate Scores\n","    # ---------------------------\n","    # Calculate emotion and sentiment scores\n","    final_score_emotion = calculate_weighted_score(audio_results_df)\n","    final_score_sentiment = calculate_weighted_score(text_results_df)\n","\n","    print(f\"Emotion Score: {final_score_emotion:.2f}\")\n","    print(f\"Sentiment Score: {final_score_sentiment:.2f}\")\n","\n","    # ---------------------------\n","    # Coherence Evaluation\n","    # ---------------------------\n","    coherence_pipeline = CoherencePipeline(\n","        dataset_path = test_data_path, # Change to '/content/dialogues_dataset.csv' if you want to train\n","        model_save_path='./coherence_model', load_model=True   # Set to False if you want to train\n","        )\n","    coherence_result = coherence_pipeline.run_pipeline()\n","    coherence_score_raw = coherence_result.loc['Overall', 'Coherence Score']\n","    coherence_score = coherence_score_raw * 10  # Assuming the raw score is between 0 and 1\n","    print(f\"Coherence Score: {coherence_score:.2f}\")\n","\n","    # ---------------------------\n","    # AHP and Fuzzy Logic Scoring\n","    # ---------------------------\n","    scoring_system = ScoringSystem()\n","    scoring_system.calculate_ahp_weights()\n","    final_score_value_no_fuzzy, final_score_value = scoring_system.perform_fuzzy_logic_scoring(\n","        final_score_emotion, final_score_sentiment, coherence_score\n","    )\n","    print(f\"Final Score (without Fuzzy Logic): {final_score_value_no_fuzzy:.2f}\")\n","    print(f\"Final Score (Defuzzified): {final_score_value:.2f}\")\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}